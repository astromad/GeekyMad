{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./.venv/lib/python3.10/site-packages (4.36.2)\n",
      "Requirement already satisfied: optimum in ./.venv/lib/python3.10/site-packages (1.16.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in ./.venv/lib/python3.10/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./.venv/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./.venv/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in ./.venv/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./.venv/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: coloredlogs in ./.venv/lib/python3.10/site-packages (from optimum) (15.0.1)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from optimum) (1.12)\n",
      "Requirement already satisfied: torch>=1.9 in ./.venv/lib/python3.10/site-packages (from optimum) (2.1.2)\n",
      "Requirement already satisfied: datasets in ./.venv/lib/python3.10/site-packages (from optimum) (2.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./.venv/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.9->optimum) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.9->optimum) (12.3.101)\n",
      "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in ./.venv/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (0.1.99)\n",
      "Requirement already satisfied: protobuf in ./.venv/lib/python3.10/site-packages (from transformers[sentencepiece]>=4.26.0->optimum) (4.25.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in ./.venv/lib/python3.10/site-packages (from coloredlogs->optimum) (10.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (0.6)\n",
      "Requirement already satisfied: dill<0.3.8,>=0.3.0 in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (0.3.7)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (2.1.4)\n",
      "Requirement already satisfied: xxhash in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (0.70.15)\n",
      "Requirement already satisfied: aiohttp in ./.venv/lib/python3.10/site-packages (from datasets->optimum) (3.9.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->optimum) (1.3.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in ./.venv/lib/python3.10/site-packages (from aiohttp->datasets->optimum) (4.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.9->optimum) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.10/site-packages (from pandas->datasets->optimum) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in ./.venv/lib/python3.10/site-packages (from pandas->datasets->optimum) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets->optimum) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip  install --upgrade transformers optimum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in ./.venv/lib/python3.10/site-packages (2.1.2)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.10/site-packages (from torch) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.venv/lib/python3.10/site-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.3.101)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -U wheel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install --upgrade auto-gptq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -v flash-attn==2.1.1 --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.2+cu121\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print (torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in ./.venv/lib/python3.10/site-packages (0.25.0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./.venv/lib/python3.10/site-packages (from accelerate) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (23.2)\n",
      "Requirement already satisfied: psutil in ./.venv/lib/python3.10/site-packages (from accelerate) (5.9.7)\n",
      "Requirement already satisfied: pyyaml in ./.venv/lib/python3.10/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in ./.venv/lib/python3.10/site-packages (from accelerate) (2.1.2)\n",
      "Requirement already satisfied: huggingface-hub in ./.venv/lib/python3.10/site-packages (from accelerate) (0.20.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in ./.venv/lib/python3.10/site-packages (from accelerate) (0.4.1)\n",
      "Requirement already satisfied: filelock in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
      "Requirement already satisfied: sympy in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
      "Requirement already satisfied: fsspec in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2023.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.18.1 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.18.1)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
      "Requirement already satisfied: triton==2.1.0 in ./.venv/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in ./.venv/lib/python3.10/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
      "Requirement already satisfied: requests in ./.venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in ./.venv/lib/python3.10/site-packages (from huggingface-hub->accelerate) (4.66.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./.venv/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.10/site-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./.venv/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: bitsandbytes in ./.venv/lib/python3.10/site-packages (0.41.3.post2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in ./.venv/lib/python3.10/site-packages (1.11.4)\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in ./.venv/lib/python3.10/site-packages (from scipy) (1.26.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in ./.venv/lib/python3.10/site-packages (8.1.1)\n",
      "Requirement already satisfied: comm>=0.1.3 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (8.19.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (5.14.1)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in ./.venv/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Requirement already satisfied: decorator in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.17.2)\n",
      "Requirement already satisfied: stack-data in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in ./.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in ./.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in ./.venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in ./.venv/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.12)\n",
      "Requirement already satisfied: executing>=1.2.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in ./.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in ./.venv/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets\n",
    "# from .autonotebook import tqdm as notebook_tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: setuptools in ./.venv/lib/python3.10/site-packages (69.0.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade setuptools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig\n",
    "compute_dtype = getattr(torch, \"float16\")\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "        load_in_4bit=True,\n",
    "        bnb_4bit_quant_type=\"nf4\",\n",
    "        bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "        bnb_4bit_use_double_quant=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3022ff98e644aca9991477028cd8272",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, pipeline\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "          model_name, quantization_config=bnb_config, device_map={\"\": 0}\n",
    ")\n",
    "# # model_name_or_path = \"TheBloke/dolphin-2.7-mixtral-8x7b-GPTQ\"\n",
    "# model_name_or_path = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "# # To use a different branch, change revision\n",
    "# # For example: revision=\"gptq-4bit-128g-actorder_True\"\n",
    "# model = AutoModelForCausalLM.from_pretrained(model_name_or_path,\n",
    "#                                                device_map=\"auto\",\n",
    "#                                                torch_dtype=torch.float16,\n",
    "#                                                offload_folder=\"offload\",\n",
    "#                                                trust_remote_code=True,\n",
    "#                                                low_cpu_mem_usage=True,\n",
    "#                                                quantization_config=bnb_config)\n",
    "                                             \n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_name_or_path, use_fast=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MixtralForCausalLM(\n",
      "  (model): MixtralModel(\n",
      "    (embed_tokens): Embedding(32000, 4096)\n",
      "    (layers): ModuleList(\n",
      "      (0-31): 32 x MixtralDecoderLayer(\n",
      "        (self_attn): MixtralAttention(\n",
      "          (q_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (k_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (v_proj): Linear4bit(in_features=4096, out_features=1024, bias=False)\n",
      "          (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
      "          (rotary_emb): MixtralRotaryEmbedding()\n",
      "        )\n",
      "        (block_sparse_moe): MixtralSparseMoeBlock(\n",
      "          (gate): Linear4bit(in_features=4096, out_features=8, bias=False)\n",
      "          (experts): ModuleList(\n",
      "            (0-7): 8 x MixtralBLockSparseTop2MLP(\n",
      "              (w1): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (w2): Linear4bit(in_features=14336, out_features=4096, bias=False)\n",
      "              (w3): Linear4bit(in_features=4096, out_features=14336, bias=False)\n",
      "              (act_fn): SiLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (input_layernorm): MixtralRMSNorm()\n",
      "        (post_attention_layernorm): MixtralRMSNorm()\n",
      "      )\n",
      "    )\n",
      "    (norm): MixtralRMSNorm()\n",
      "  )\n",
      "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import  AutoTokenizer\n",
    "\n",
    "#Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, add_eos_token=True, use_fast=True)\n",
    "tokenizer.pad_token = tokenizer.unk_token\n",
    "tokenizer.pad_token_id =  tokenizer.unk_token_id\n",
    "tokenizer.padding_side = 'left'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=\"Summarize your thoughts on AI hallucinations\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s> Summarize your thoughts on AI hallucinations</s>ef{sec:hallucination}\n",
      "\n",
      "AI hallucinations are a significant challenge in the development and deployment of large language models like me. They refer to situations where the model generates text that is coherent and fluent but factually incorrect or nonsensical. This can occur due to various reasons, such as the model's training data containing errors or contradictions, or the model's inability to distinguish between real and fake information.\n",
      "\n",
      "Hallucinations can have serious consequences, especially in high-stakes applications such as healthcare, finance, or legal contexts. Therefore, it is crucial to address this issue and find ways to mitigate it. One approach is to improve the quality and diversity of the training data, ensuring that it is as accurate and consistent as possible. Another approach is to develop post-hoc evaluation methods that can detect and flag instances of hallucination in the model's outputs. Additionally, incorporating more interpretable and explainable models can help us understand when and why hallucinations occur, allowing us to design better strategies for preventing them.\n",
      "\n",
      "Overall, while AI hallucinations are a significant challenge, they also present an opportunity to improve the transparency, accountability, and reliability of large language models. By addressing this issue, we can build more trustworthy and responsible AI systems that better serve the needs of society.</s>\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer.encode(prompt, return_tensors='pt',padding=True).cuda()\n",
    "output = model.generate(inputs=input_ids, pad_token_id=tokenizer.unk_token_id,do_sample=True,temperature=0.4, repetition_penalty=1.1, top_p=0.95, top_k=40, max_new_tokens=512).cuda()\n",
    "print(tokenizer.decode(output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Pipeline:\n",
      "Summarize your thoughts on AI hallucinations and the importance of building trust with users.\n",
      "\n",
      "AI hallucinations are a significant issue that can lead to mistrust and misinformation. They occur when an AI model generates outputs that are factually incorrect or nonsensical. This problem is particularly prevalent in language models, where the model might generate plausible-sounding but entirely made-up information.\n",
      "\n",
      "To build trust with users, it's crucial to acknowledge this issue and be transparent about the limitations of AI technology. Developers should implement strategies to detect and mitigate hallucinations, such as using multiple models to cross-check results or incorporating fact-checking mechanisms. Additionally, educating users about the capabilities and limitations of AI can help manage expectations and foster a more realistic understanding of the technology. By being proactive in addressing AI hallucinations and promoting transparency, we can work towards building a stronger relationship of trust between humans and AI systems.\n"
     ]
    }
   ],
   "source": [
    "print(\"*** Pipeline:\")\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    max_new_tokens=512,\n",
    "    pad_token_id=tokenizer.unk_token_id,\n",
    "    do_sample=True,\n",
    "    temperature=0.4,\n",
    "    top_p=0.95,\n",
    "    top_k=40,\n",
    "    repetition_penalty=1.1\n",
    ")\n",
    "\n",
    "print(pipe(prompt)[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*** Prompt:\n",
      "<s> [INST] Tell me a recipe for Upma. [/INST]\n",
      "\n",
      "\n",
      "*** Generate:\n",
      "Sure, here's a simple recipe for Upma, a popular Indian breakfast dish made with semolina:\n",
      "\n",
      "Ingredients:\n",
      "\n",
      "* 1 cup semolina (rava)\n",
      "* 2 tablespoons oil or ghee\n",
      "* 1 teaspoon mustard seeds\n",
      "* 1 teaspoon cumin seeds\n",
      "* 1 onion, finely chopped\n",
      "* 2 green chilies, finely chopped\n",
      "* 1 teaspoon ginger, grated or minced\n",
      "* 1 teaspoon curry leaves (optional)\n",
      "* 1 cup mixed vegetables (such as peas, carrots, beans, and corn)\n",
      "* 2 cups water\n",
      "* 1 teaspoon salt (or to taste)\n",
      "* 1/2 teaspoon turmeric powder\n",
      "* 1/2 teaspoon coriander powder\n",
      "* 1/4 teaspoon cumin powder\n",
      "* 1/4 teaspoon garam masala\n",
      "* 2 tablespoons lemon juice\n",
      "* 2 tablespoons chopped cilantro\n",
      "\n",
      "Instructions:\n",
      "\n",
      "1. Dry roast the semolina in a pan over medium heat until it turns light brown and gives off a nutty aroma. Transfer to a plate and set aside.\n",
      "2. Heat oil or ghee in the same pan over medium heat. Add mustard seeds and cumin seeds and let them crackle.\n",
      "3. Add onion, green chilies, ginger, and curry leaves (if using) and sauté until the onion turns golden brown.\n",
      "4. Add mixed vegetables and sauté for 2-3 minutes until they are partially cooked.\n",
      "5. In a separate pot, bring water to a boil. Add salt, turmeric powder, coriander powder, cumin powder, and garam masala.\n",
      "6. Gradually add the roasted semolina to the pan while stirring continuously to avoid lumps.\n",
      "7. Pour the boiling water over the semolina mixture and stir well.\n",
      "8. Reduce the heat to low, cover the pan, and let it cook for 2-3 minutes until the semolina has absorbed all the water and become soft and fluffy.\n",
      "9. Stir in lemon juice and chopped cilantro.\n",
      "10. Serve hot with chutney or ketchup.\n",
      "\n",
      "Note: You can adjust the quantity and type of vegetables according to your preference. You can also add nuts like cashews or raisins for extra flavor and texture.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a recipe for Upma.\"},\n",
    "]\n",
    "\n",
    "print(\"\\n\\n*** Prompt:\")\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "print(tokenizer.decode(input_ids[0]))\n",
    "\n",
    "print(\"\\n\\n*** Generate:\")\n",
    "with torch.autocast(\"cuda\", dtype=torch.bfloat16):\n",
    "    output = model.generate(\n",
    "        input_ids=input_ids.to(\"cuda\"),\n",
    "        max_new_tokens=1024,\n",
    "        return_dict_in_generate=True,\n",
    "    )\n",
    "\n",
    "response = tokenizer.decode(\n",
    "    output[\"sequences\"][0][len(input_ids[0]):], \n",
    "    skip_special_tokens=True\n",
    ")\n",
    "print(response)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
