{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOCOBoubq1gfwB4CtD1q/bh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e03943f677c745b197f5870e7c18f660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_306f6c0fb78a4f96a574d06af8cebc7b",
              "IPY_MODEL_df58668cc4a84325872c38740c3b7dc3",
              "IPY_MODEL_d766868012df4ddca4524d8ad4a8d141"
            ],
            "layout": "IPY_MODEL_1d80fc3685ab4033990bf59565f6352b"
          }
        },
        "306f6c0fb78a4f96a574d06af8cebc7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50289b21a84f40f89e793d2b152f3121",
            "placeholder": "​",
            "style": "IPY_MODEL_ec71347c928b421e84eae1427bbed995",
            "value": "model.safetensors: 100%"
          }
        },
        "df58668cc4a84325872c38740c3b7dc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_61704b51325a49208123c5d33fa033bb",
            "max": 548105171,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fbdd440b17244988b69c5c008dfb86f",
            "value": 548105171
          }
        },
        "d766868012df4ddca4524d8ad4a8d141": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b74409e23bad4c9eb3b7176b11db6aa3",
            "placeholder": "​",
            "style": "IPY_MODEL_621ef9d0cd8945af8d0f24bbacdca0ec",
            "value": " 548M/548M [00:04&lt;00:00, 106MB/s]"
          }
        },
        "1d80fc3685ab4033990bf59565f6352b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50289b21a84f40f89e793d2b152f3121": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec71347c928b421e84eae1427bbed995": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "61704b51325a49208123c5d33fa033bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fbdd440b17244988b69c5c008dfb86f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b74409e23bad4c9eb3b7176b11db6aa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "621ef9d0cd8945af8d0f24bbacdca0ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/astromad/GeekyMad/blob/main/LLMTraining_Part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What is Task Specific Fine-tuning\n",
        "\n",
        "* Fine Tuning and Instruction Fine Tuning (IFT)\n",
        "  * Expensive\n",
        "  * All Model parameters modified\n",
        "  * Catastrophic forgetting\n",
        "* Perameter Efficient Fine Tuning (PEFT)\n",
        "  * Only few (new) parameres gets modified\n",
        "  * Cost efficient\n",
        "  * Original weights frozen"
      ],
      "metadata": {
        "id": "DqZolup4QjBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[AutoModelForSequenceClassification](https://huggingface.co/transformers/v3.0.2/model_doc/auto.html#automodelforsequenceclassification)\n",
        "\n",
        "[GPT-2](https://huggingface.co/transformers/v3.0.2/model_doc/gpt2.html#gpt2doubleheadsmodel)"
      ],
      "metadata": {
        "id": "MsImALS8TCnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nBZm0D5ZCibI",
        "outputId": "1c387d5a-7578-4803-a954-8fa1ab51e0c6"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Finetune GPT-2 for product Classification**\n",
        "\n",
        "Product classification is a challenging task for many companies, With thousands of new products getting added to ecommerce sites, unless they are able to categorize them properly, products won’t be able to show up for the right customers and would not be able to sell as a result. This is a field of study in machine learning. In this project, I will walk you through the advantages of finetuning GPT-2 to solve classification problem bit more efficiently.\n",
        "\n"
      ],
      "metadata": {
        "id": "AIAKzZxwI5yx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean up previous training data\n",
        "!rm -rf Classification_cache\n",
        "!rm -rf results_PT\n",
        "!rm -rf logs_PT"
      ],
      "metadata": {
        "id": "yAvfkb6rMmvw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers"
      ],
      "metadata": {
        "id": "UivCEHu3TKkn"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate -U"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-WSnvrwf29x",
        "outputId": "ad1f6785-072d-48f4-95b1-8cf5b7b6affe"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.24.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu118)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the training data, in our case it's Amazon dataset. Data set is in csv format and has 3 columns:\n",
        "\n",
        "* Product Category\n",
        "* Product Label\n",
        "* Product Description\n",
        "\n",
        "In this section , we will\n",
        "\n",
        "* Read the datset and load it as Pandas Data frame\n",
        "* Clan the data by removing entries with 'null' category"
      ],
      "metadata": {
        "id": "hbHp7-SCNJ0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"/content/drive/My Drive/ColabData/Amazon.csv\",\n",
        "                encoding=\"ISO-8859-1\", error_bad_lines=False)\n",
        "\n",
        "data = df[['category', 'label_title', 'label_description']]\n",
        "data.dropna(subset=['category'], inplace=True)\n",
        "print(data.head(3))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAePQhhSvRGJ",
        "outputId": "11590f9a-b232-461e-bab1-a257a113eb2d"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-54-ddeba6b54d8c>:2: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(\"/content/drive/My Drive/ColabData/Amazon.csv\",\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                category                                        label_title  \\\n",
            "0  Headphone Accessories                  Koss EQ50 3-Band Stereo Equalizer   \n",
            "1     Inkjet Printer Ink              Kodak Black Ink Cartridge 10B 1163641   \n",
            "2  Computers Accessories  Kingston 128MX64 PC2700 COMPAQ Evo D320 KTC-D3...   \n",
            "\n",
            "                                   label_description  \n",
            "0  The pocket-size Koss 3-Band Equalizer delivers...  \n",
            "1  Kodak Black Ink Cartridge 10B is a standard bl...  \n",
            "2  1GB - 333MHz DDR333 PC2700 - DDR SDRAM - 184-p...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to do some cleanup to remove outliers. Current data has 706 unique categories but many of them have less than 20 products, this is just to improve training time by focussing on categories with larger number of products. With this our category count drops to less than 200"
      ],
      "metadata": {
        "id": "DP9qhWYTNts_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(data.groupby('category').count() )\n",
        "\n",
        "value_counts = data['category'].value_counts()\n",
        "to_remove = value_counts[value_counts <= 20].index\n",
        "data = data[~data.category.isin(to_remove)]\n",
        "\n",
        "print(data.groupby('category').count() )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uwrbMHnkvdXe",
        "outputId": "1b62ef04-8d64-4d76-8e7d-ca7e835f855a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           label_title  label_description\n",
            "category                                                 \n",
            "12V                                  1                  1\n",
            "6V                                   4                  4\n",
            "9V                                   6                  6\n",
            "A                                    2                  2\n",
            "AA                                  22                 22\n",
            "...                                ...                ...\n",
            "Wires                                1                  1\n",
            "Wiring Harnesses                    20                 20\n",
            "Wrist Rests                         17                 17\n",
            "eBook Readers                       12                 12\n",
            "eBook Readers Accessories            6                  6\n",
            "\n",
            "[706 rows x 2 columns]\n",
            "                        label_title  label_description\n",
            "category                                              \n",
            "AA                               22                 22\n",
            "AC Adapters                      38                 38\n",
            "Accessories                     119                118\n",
            "Accessories Supplies            226                225\n",
            "Accessory Kits                   77                 75\n",
            "...                             ...                ...\n",
            "Video Projectors                106                105\n",
            "Wall Chargers                    23                 23\n",
            "Webcams                          76                 76\n",
            "Wired Headsets                   28                 28\n",
            "Wireless Access Points           25                 25\n",
            "\n",
            "[188 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now if we want to use this data, we need target class to be numerical to feed it in to ML/DL models, So converting category to a numerical value"
      ],
      "metadata": {
        "id": "V3FNk-yKN68h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "encode_dict={}\n",
        "def encode_label(x):\n",
        "    if x not in encode_dict.keys():\n",
        "        encode_dict[x]=len(encode_dict)\n",
        "    return encode_dict[x]\n",
        "\n",
        "data['encoded_category'] = data['category'].apply(lambda x: encode_label(x))"
      ],
      "metadata": {
        "id": "w55uAl9dvdQ9"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our data has two text fields, one Label title and label description, We are merging both of them to form one text field to feed it to our model to classify"
      ],
      "metadata": {
        "id": "cpoRTkRaOCjX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newData=pd.DataFrame()\n",
        "newData['desc']=data['label_title'] +' '+ data['label_description']\n",
        "newData['encoded_category']=data['encoded_category']\n"
      ],
      "metadata": {
        "id": "sUrVNI_gvdGe"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reset the index of our data as we removed some null category data\n"
      ],
      "metadata": {
        "id": "_tKXLXtwONGJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(newData[:21])\n",
        "newData = newData.reset_index(drop=True)\n",
        "print(newData[:21])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vcs6XQB9vvu5",
        "outputId": "3c160d10-60f2-400b-a15f-693367a02105"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                 desc  encoded_category\n",
            "0   Koss EQ50 3-Band Stereo Equalizer The pocket-s...                 0\n",
            "1   Kodak Black Ink Cartridge 10B 1163641 Kodak Bl...                 1\n",
            "2   Kingston 128MX64 PC2700 COMPAQ Evo D320 KTC-D3...                 2\n",
            "3   Kinamax MS-UES2 Mini High Precision USB 3-Butt...                 3\n",
            "4   Kensington K72349US Wireless Mouse for Netbook...                 3\n",
            "5   Kensington BlackBelt Protection Band for iPad ...                 4\n",
            "6   JUST5 J509 Easy to Use Unlocked Cell Phone wit...                 5\n",
            "7   Imation Corp 50PK CDR 700MB 80MIN 52X-SPINDLE ...                 6\n",
            "8   16x DVD-R Media Imation 16x DVD-R Media 17340 ...                 7\n",
            "9   iGo Arctic Laptop Cooling Pad AC05065-0001 Eve...                 8\n",
            "10  HP TouchPad Custom Fit Case Protect your HP To...                 9\n",
            "11  HP LaserJet Pro P1606dn Printer CE749A BGJ WHY...                10\n",
            "12  HP 85A LaserJet Black Toner Print Cartridge - ...                11\n",
            "13  HP - Envelope feeder - 75 sheets 75 Sheet Lase...                12\n",
            "14  Hawking Hi-Gain Outdoor Wireless-300N Dual Rad...                13\n",
            "15  Griffin Technology PowerJolt SE 2 amp Power Ch...                14\n",
            "18  Fujitsu ScanSnap S1500M Instant PDF Sheet-Fed ...                15\n",
            "19  Slim Folding Multi-Position Tablet Stand for G...                16\n",
            "21  Emerge Tech Retractable USB Cable for iPod Whi...                17\n",
            "22  Ematic 10 in 1 Premium Accessory Kit for iPod ...                17\n",
            "23  EDGE SD Gaming Cards - Flash memory card - 1 G...                18\n",
            "                                                 desc  encoded_category\n",
            "0   Koss EQ50 3-Band Stereo Equalizer The pocket-s...                 0\n",
            "1   Kodak Black Ink Cartridge 10B 1163641 Kodak Bl...                 1\n",
            "2   Kingston 128MX64 PC2700 COMPAQ Evo D320 KTC-D3...                 2\n",
            "3   Kinamax MS-UES2 Mini High Precision USB 3-Butt...                 3\n",
            "4   Kensington K72349US Wireless Mouse for Netbook...                 3\n",
            "5   Kensington BlackBelt Protection Band for iPad ...                 4\n",
            "6   JUST5 J509 Easy to Use Unlocked Cell Phone wit...                 5\n",
            "7   Imation Corp 50PK CDR 700MB 80MIN 52X-SPINDLE ...                 6\n",
            "8   16x DVD-R Media Imation 16x DVD-R Media 17340 ...                 7\n",
            "9   iGo Arctic Laptop Cooling Pad AC05065-0001 Eve...                 8\n",
            "10  HP TouchPad Custom Fit Case Protect your HP To...                 9\n",
            "11  HP LaserJet Pro P1606dn Printer CE749A BGJ WHY...                10\n",
            "12  HP 85A LaserJet Black Toner Print Cartridge - ...                11\n",
            "13  HP - Envelope feeder - 75 sheets 75 Sheet Lase...                12\n",
            "14  Hawking Hi-Gain Outdoor Wireless-300N Dual Rad...                13\n",
            "15  Griffin Technology PowerJolt SE 2 amp Power Ch...                14\n",
            "16  Fujitsu ScanSnap S1500M Instant PDF Sheet-Fed ...                15\n",
            "17  Slim Folding Multi-Position Tablet Stand for G...                16\n",
            "18  Emerge Tech Retractable USB Cable for iPod Whi...                17\n",
            "19  Ematic 10 in 1 Premium Accessory Kit for iPod ...                17\n",
            "20  EDGE SD Gaming Cards - Flash memory card - 1 G...                18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newData.dropna(subset=['desc'], inplace=True)\n",
        "nan_rows = newData[newData.isnull().T.any()]\n",
        "print(nan_rows)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PPEOsWjXvc6L",
        "outputId": "ba3ca6fb-4336-4134-c547-82e9eca78faf"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Empty DataFrame\n",
            "Columns: [desc, encoded_category]\n",
            "Index: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing on description text data, remove stop words, remove spaces, lowercase note: we are not lemmatize as Bert will take care of it"
      ],
      "metadata": {
        "id": "R3e8YbAQOknI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "newData.loc[20,'desc']"
      ],
      "metadata": {
        "id": "8m7tSc8cOoF-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "61e5e816-6cf3-4787-df75-ff7248afee47"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'EDGE SD Gaming Cards - Flash memory card - 1 GB - 130x - SD Edge Tech Corp 1GB Secure Digital SD Gaming Card EDGDM-222666-PE Flash Memory'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lP2_Es6Ivcrt",
        "outputId": "61cb11a3-89f5-4a0e-eea5-07f92b524823"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newData['desc']=newData.desc.str.replace(\"[^\\w\\s]\", \"\").str.lower()\n",
        "newData['desc']=newData['desc'].apply(lambda x: ' '.join([item for item in x.split() if item not in stop]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2pYV3TIv4wC",
        "outputId": "f2ef5f6a-fcbf-448d-819a-9f2429038e0b"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-62-2d1ebb506104>:1: FutureWarning: The default value of regex will change from True to False in a future version.\n",
            "  newData['desc']=newData.desc.str.replace(\"[^\\w\\s]\", \"\").str.lower()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "newData.loc[20,'desc']"
      ],
      "metadata": {
        "id": "nS-HEgfTOwji",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "2702ca19-a853-4c24-f089-4d9484f2084b"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'edge sd gaming cards flash memory card 1 gb 130x sd edge tech corp 1gb secure digital sd gaming card edgdm222666pe flash memory'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from future.utils import iteritems\n",
        "label2idx = {t: i for i, t in enumerate(encode_dict)}\n",
        "idx2label = {v: k for k, v in iteritems(label2idx)}"
      ],
      "metadata": {
        "id": "ZcXQEXq4v4sq"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ClassMax=newData['encoded_category'].max()\n",
        "print('Number of Categories of products',ClassMax)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K85DW5uwv4o1",
        "outputId": "ea163386-0c7e-40c9-b5b0-235311f6cd84"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Categories of products 187\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_size = 0.8\n",
        "train_dataset=newData.sample(frac=train_size,random_state=200)\n",
        "test_dataset=newData.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "\n",
        "print(\"FULL Dataset: {}\".format(newData.shape))\n",
        "print(\"TRAIN Dataset: {}\".format(train_dataset.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_dataset.shape))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04qKmOQPv4dV",
        "outputId": "497c06c6-2a55-455e-f25c-bbbc961fc4a4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FULL Dataset: (18046, 2)\n",
            "TRAIN Dataset: (14437, 2)\n",
            "TEST Dataset: (3609, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "LEARNING_RATE = 3e-02"
      ],
      "metadata": {
        "id": "fmB74IBLwFeS"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using GPT-2 model and it's Tokenizer"
      ],
      "metadata": {
        "id": "yBtQQ2joPMNd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoTokenizer\n",
        ")\n",
        "model_args = dict()\n",
        "model_args['model_name'] = 'gpt2'\n",
        "model_args['cache_dir'] = \"Classification_cache/\"\n",
        "model_args['do_basic_tokenize'] = False\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    model_args['model_name'],\n",
        "    cache_dir=model_args['cache_dir'],\n",
        "    is_pretokenized=model_args['do_basic_tokenize'],\n",
        "    do_basic_tokenize = model_args['do_basic_tokenize']\n",
        ")\n",
        "config = AutoConfig.from_pretrained(\n",
        "    model_args['model_name'],\n",
        "    cache_dir=model_args['cache_dir'],\n",
        "    return_dict=True,\n",
        "    pad_token_id=tokenizer.eos_token_id,\n",
        "    id2label=idx2label,\n",
        "    label2id=label2idx,\n",
        "    num_labels=ClassMax+1\n",
        ")\n"
      ],
      "metadata": {
        "id": "44rx_cnxwSfW"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch.nn as nn\n",
        "\n",
        "# Adding a custom classification head on top of the pre-trained model\n",
        "# num_classes = x\n",
        "# classification_head = nn.Linear(model.config.hidden_size, num_classes)\n",
        "\n",
        "# # Replace the pre-trained model's classification head with our custom head\n",
        "# model.classifier = classification_head"
      ],
      "metadata": {
        "id": "FW8u45ZuFxut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's define function to create input dataset that transformer model understands, this function reads each Description and category and arrange it into 4 sections:\n",
        "\n",
        "* Input_ids\n",
        "* token_type_ids\n",
        "* attention_masks\n",
        "* label_ids\n",
        "\n",
        "We use tokenizer.encode_plus to further tokenize each words and we add corresponding labels to the list.\n",
        "\n",
        "We do this for both Training and Test datasets"
      ],
      "metadata": {
        "id": "C9KRkt7bPcWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decorate(description):\n",
        "    start_prompt = 'Classify the following product description.\\n\\n'\n",
        "    end_prompt = '\\n\\nProduct Category: '\n",
        "    prompt = start_prompt + description + end_prompt\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "TSj3Yiz9F1qU"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import re\n",
        "class TorchClassificationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,dataset,max_len):\n",
        "        self.len = len(dataset)\n",
        "        self.data = dataset\n",
        "        self.max_len=max_len\n",
        "    def __getitem__(self, idx):\n",
        "        description = str(self.data.desc[idx])\n",
        "        description = description[:self.max_len]\n",
        "        # print(description)\n",
        "        inputs = tokenizer.encode_plus(\n",
        "            decorate(description),\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            return_token_type_ids=True,\n",
        "            truncation=True\n",
        "        )\n",
        "        item ={}\n",
        "        item['input_ids']=torch.tensor(inputs['input_ids'], dtype=torch.long)\n",
        "        item['token_type_ids']=torch.tensor(inputs['token_type_ids'], dtype=torch.long)\n",
        "        item['attention_mask']=torch.tensor(inputs['attention_mask'], dtype=torch.long)\n",
        "        item['labels'] = torch.tensor(self.data.encoded_category[idx], dtype=torch.long)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.len"
      ],
      "metadata": {
        "id": "055dRtJYq_HG"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def createDataset(framework='pt'):\n",
        "  if framework=='pt':\n",
        "    train_ds = TorchClassificationDataset(train_dataset,MAX_LEN)\n",
        "    test_ds= TorchClassificationDataset(test_dataset,MAX_LEN)\n",
        "  return train_ds,test_ds"
      ],
      "metadata": {
        "id": "iOoxUWwtyl5s"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the data is available in the format token classification model expects, let's prepare for training the model. As the data need to be fed in batches to take advantage of efficient distribution of data to train to each worker, This data need to be converted to tensors and be part of Data loader for PyTorch model to read, What this following class doing is preparing data in a dictionary for model to read"
      ],
      "metadata": {
        "id": "c8t7ErILQAaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds,test_ds = createDataset('pt')"
      ],
      "metadata": {
        "id": "wO-uVURnrFfG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.pad_token = tokenizer.eos_token"
      ],
      "metadata": {
        "id": "zH2Slpjfypj1"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('One record of Training dataset')\n",
        "print(train_ds[0])\n",
        "print('One record of Test dataset')\n",
        "print(test_ds[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_RRdI1-brbuU",
        "outputId": "b19eb270-85ab-464f-ef88-b44af7c433c4"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One record of Training dataset\n",
            "{'input_ids': tensor([ 9487,  1958,   262,  1708,  1720,  6764,    13,   198,   198,  6404,\n",
            "        45396, 26250,    79, 49823,   269, 44928, 49823,   269, 44928, 30902,\n",
            "         3033, 11711, 26250,    79,  5861,   266,  1460, 32060,   362, 29034,\n",
            "          289,    67, 12694,   374,  1031,   669,    71,  5117,  2008,  4882,\n",
            "         4352,   461,   198,   198, 15667, 21743,    25,   220, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(60)}\n",
            "One record of Test dataset\n",
            "{'input_ids': tensor([ 9487,  1958,   262,  1708,  1720,  6764,    13,   198,   198,  5116,\n",
            "          321,   897, 13845,   947,    17,  9927,  1029, 15440, 38551,   513,\n",
            "        16539,   513,    67, 18480, 10743,  7825, 10211, 34449,   540,  7862,\n",
            "         2042, 18967,   321,   897, 13845,   947,    17,  9927,  1029,   778,\n",
            "          198,   198, 15667, 21743,    25,   220, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
            "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256]), 'token_type_ids': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'attention_mask': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "        0, 0, 0, 0, 0, 0, 0, 0]), 'labels': tensor(3)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any Machine learning model to evaluate the performance we do via Accuracy, Precision, Recall & F1 Score metrics. Here I am using sklearn metrics library to measure these."
      ],
      "metadata": {
        "id": "R1_DUAc7QIEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "metadata": {
        "id": "2Kq4IRY0wmm4"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ok, As you have seen, majority of the machine learning task is to get the data ready for the model to train. Now let's use Hugginface's new Trainer module to train the model"
      ],
      "metadata": {
        "id": "ca7LVA5qQTuN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    TrainingArguments\n",
        ")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_args['model_name'],\n",
        "    config=config,\n",
        "    cache_dir=model_args['cache_dir'],\n",
        ")\n"
      ],
      "metadata": {
        "id": "e_ieNIq6w8AU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "e03943f677c745b197f5870e7c18f660",
            "306f6c0fb78a4f96a574d06af8cebc7b",
            "df58668cc4a84325872c38740c3b7dc3",
            "d766868012df4ddca4524d8ad4a8d141",
            "1d80fc3685ab4033990bf59565f6352b",
            "50289b21a84f40f89e793d2b152f3121",
            "ec71347c928b421e84eae1427bbed995",
            "61704b51325a49208123c5d33fa033bb",
            "5fbdd440b17244988b69c5c008dfb86f",
            "b74409e23bad4c9eb3b7176b11db6aa3",
            "621ef9d0cd8945af8d0f24bbacdca0ec"
          ]
        },
        "outputId": "ff1565a8-c1e5-425c-9c0e-3c39253ee12d"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e03943f677c745b197f5870e7c18f660"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7K6POuUPV98",
        "outputId": "6ddac67e-57a4-4dac-bd29-e9499cfbb657"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (0.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft) (2.1.0+cu118)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft) (4.35.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft) (4.66.1)\n",
            "Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft) (0.24.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft) (0.4.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->peft) (0.19.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft) (2.1.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft) (0.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig,get_peft_model\n",
        "\n",
        "peft_config = LoraConfig(\n",
        "    lora_alpha=16,\n",
        "    lora_dropout=0.1,\n",
        "    r=64,\n",
        "    bias=\"none\",\n",
        "    fan_in_fan_out=True,\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")"
      ],
      "metadata": {
        "id": "Q3n-6fSbMjma"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ],
      "metadata": {
        "id": "7YsnEt9FbetB"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_trainable_parameters(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXTQo5qVbhED",
        "outputId": "734252ec-3b5f-4059-9a94-a615fcb05245"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 124584192 || all params: 124584192 || trainable%: 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "peftmodel = get_peft_model(model, peft_config)"
      ],
      "metadata": {
        "id": "oJFVbqC1Mo-V"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('After Peft:',peftmodel.print_trainable_parameters())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U15FCnjcRbc2",
        "outputId": "11503108-033c-46ad-f1b4-10c7e0434d30"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,503,680 || all params: 127,087,872 || trainable%: 1.9700384943104563\n",
            "After Peft: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='./results_PT',\n",
        "    num_train_epochs=10,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs_PT',\n",
        "    logging_steps=3,\n",
        "    #learning_rate=LEARNING_RATE\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=peftmodel,\n",
        "    args=training_args,\n",
        "    train_dataset=train_ds,\n",
        "    eval_dataset=test_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "MRydd2-oOg-1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "dMvsYjTeOnN1",
        "outputId": "efde8fd5-bbea-472f-e4d1-3e6be958adb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-6de989b32cb1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'ha' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "Lwpey2ugw-Z4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.evaluate()"
      ],
      "metadata": {
        "id": "LT0QeepCxCMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peftmodelDir=\"/content/drive/MyDrive/ColabData/SAVED-MODELS/gpt2-Classify-PEFT-model\"\n",
        "basemodelDir=\"/content/drive/MyDrive/ColabData/SAVED-MODELS/gpt2-Classify-BASE-model\"\n"
      ],
      "metadata": {
        "id": "-owOkToyPL8B"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peftmodel.save_pretrained(peftmodelDir,push_to_hub=False)\n",
        "peftmodel.base_model.save_pretrained(basemodelDir,push_to_hub=False)\n",
        "tokenizer.save_pretrained(basemodelDir, push_to_hub=False)"
      ],
      "metadata": {
        "id": "qUyTkJ5vB0li"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import PeftModel,PeftConfig\n",
        "from transformers import (\n",
        "    AutoModelForSequenceClassification,\n",
        "    Trainer,\n",
        "    AutoTokenizer,\n",
        "    TrainingArguments\n",
        ")\n",
        "import torch"
      ],
      "metadata": {
        "id": "kVXI-c28aJvL"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model(basemodelDir,peftmodelDir):\n",
        "  bModel=AutoModelForSequenceClassification.from_pretrained(basemodelDir)\n",
        "  peftModel=PeftModel.from_pretrained(bModel,peftmodelDir,strict=False,remove_module=True)\n",
        "  return peftModel\n",
        "def load_tokenizer(basemodelDir):\n",
        "  tokenizer = AutoTokenizer.from_pretrained(basemodelDir)\n",
        "  return tokenizer"
      ],
      "metadata": {
        "id": "ZdIW8xtuDLwE"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trained_model = load_model(basemodelDir,peftmodelDir)\n",
        "tokenizer = load_tokenizer(basemodelDir)"
      ],
      "metadata": {
        "id": "U0Vx8MP3eNe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f2d86a9-5820-4b3f-ede5-7cd7c326ab61"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at /content/drive/MyDrive/ColabData/SAVED-MODELS/gpt2-Classify-BASE-model were not used when initializing GPT2ForSequenceClassification: ['transformer.h.7.attn.c_attn.lora_B.default.weight', 'transformer.h.11.attn.c_attn.lora_A.default.weight', 'transformer.h.8.attn.c_attn.lora_B.default.weight', 'score.modules_to_save.default.weight', 'transformer.h.2.attn.c_attn.lora_B.default.weight', 'transformer.h.8.attn.c_attn.lora_A.default.weight', 'transformer.h.3.attn.c_attn.lora_A.default.weight', 'transformer.h.4.attn.c_attn.lora_A.default.weight', 'transformer.h.0.attn.c_attn.lora_A.default.weight', 'transformer.h.2.attn.c_attn.lora_A.default.weight', 'transformer.h.6.attn.c_attn.lora_B.default.weight', 'transformer.h.7.attn.c_attn.lora_A.default.weight', 'score.original_module.weight', 'transformer.h.6.attn.c_attn.lora_A.default.weight', 'transformer.h.5.attn.c_attn.lora_A.default.weight', 'transformer.h.3.attn.c_attn.lora_B.default.weight', 'transformer.h.1.attn.c_attn.lora_B.default.weight', 'transformer.h.10.attn.c_attn.lora_A.default.weight', 'transformer.h.10.attn.c_attn.lora_B.default.weight', 'transformer.h.9.attn.c_attn.lora_B.default.weight', 'transformer.h.5.attn.c_attn.lora_B.default.weight', 'transformer.h.11.attn.c_attn.lora_B.default.weight', 'transformer.h.1.attn.c_attn.lora_A.default.weight', 'transformer.h.9.attn.c_attn.lora_A.default.weight', 'transformer.h.0.attn.c_attn.lora_B.default.weight', 'transformer.h.4.attn.c_attn.lora_B.default.weight']\n",
            "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at /content/drive/MyDrive/ColabData/SAVED-MODELS/gpt2-Classify-BASE-model and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_text(model,sequence, max_length):\n",
        "    ids = tokenizer(sequence, return_tensors='pt')\n",
        "    model.to('cpu')\n",
        "    final_outputs = model(**ids,labels=torch.tensor([10]).unsqueeze(0))\n",
        "    print('Category is',idx2label[final_outputs.logits.argmax(-1).detach().numpy()[0]])\n",
        "    # print(tokenizer.decode(final_outputs[1], skip_special_tokens=True))"
      ],
      "metadata": {
        "id": "Nn-RBCbh_CdF"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "desc=\"TRENDnet 150 Mbps Mini Wireless N USB 2.0 Adapter TEW-648UB Black\"\n",
        "prompt = decorate(desc)\n",
        "print(prompt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nudI8dbgGPZB",
        "outputId": "7504c72b-264d-4a86-f5b1-5ae96d1dc9e2"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classify the following product description.\n",
            "\n",
            "TRENDnet 150 Mbps Mini Wireless N USB 2.0 Adapter TEW-648UB Black\n",
            "\n",
            "Product Category: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(trained_model,prompt,500)"
      ],
      "metadata": {
        "id": "lYvjCA0_BQ-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c02276-f43e-4912-e7db-9ff34e7086b7"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Category is USB Network Adapters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "classification_pipe = pipeline(\"text-classification\", model=trained_model, tokenizer=tokenizer ,device='cpu')\n",
        "output=classification_pipe(prompt)\n",
        "print(output[0]['label'])"
      ],
      "metadata": {
        "id": "hbF7vrbO7tRL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d924d5df-502f-4034-fffc-fd51f752133d"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The model 'PeftModelForSequenceClassification' is not supported for text-classification. Supported models are ['AlbertForSequenceClassification', 'BartForSequenceClassification', 'BertForSequenceClassification', 'BigBirdForSequenceClassification', 'BigBirdPegasusForSequenceClassification', 'BioGptForSequenceClassification', 'BloomForSequenceClassification', 'CamembertForSequenceClassification', 'CanineForSequenceClassification', 'LlamaForSequenceClassification', 'ConvBertForSequenceClassification', 'CTRLForSequenceClassification', 'Data2VecTextForSequenceClassification', 'DebertaForSequenceClassification', 'DebertaV2ForSequenceClassification', 'DistilBertForSequenceClassification', 'ElectraForSequenceClassification', 'ErnieForSequenceClassification', 'ErnieMForSequenceClassification', 'EsmForSequenceClassification', 'FalconForSequenceClassification', 'FlaubertForSequenceClassification', 'FNetForSequenceClassification', 'FunnelForSequenceClassification', 'GPT2ForSequenceClassification', 'GPT2ForSequenceClassification', 'GPTBigCodeForSequenceClassification', 'GPTNeoForSequenceClassification', 'GPTNeoXForSequenceClassification', 'GPTJForSequenceClassification', 'IBertForSequenceClassification', 'LayoutLMForSequenceClassification', 'LayoutLMv2ForSequenceClassification', 'LayoutLMv3ForSequenceClassification', 'LEDForSequenceClassification', 'LiltForSequenceClassification', 'LlamaForSequenceClassification', 'LongformerForSequenceClassification', 'LukeForSequenceClassification', 'MarkupLMForSequenceClassification', 'MBartForSequenceClassification', 'MegaForSequenceClassification', 'MegatronBertForSequenceClassification', 'MistralForSequenceClassification', 'MobileBertForSequenceClassification', 'MPNetForSequenceClassification', 'MptForSequenceClassification', 'MraForSequenceClassification', 'MT5ForSequenceClassification', 'MvpForSequenceClassification', 'NezhaForSequenceClassification', 'NystromformerForSequenceClassification', 'OpenLlamaForSequenceClassification', 'OpenAIGPTForSequenceClassification', 'OPTForSequenceClassification', 'PerceiverForSequenceClassification', 'PersimmonForSequenceClassification', 'PLBartForSequenceClassification', 'QDQBertForSequenceClassification', 'ReformerForSequenceClassification', 'RemBertForSequenceClassification', 'RobertaForSequenceClassification', 'RobertaPreLayerNormForSequenceClassification', 'RoCBertForSequenceClassification', 'RoFormerForSequenceClassification', 'SqueezeBertForSequenceClassification', 'T5ForSequenceClassification', 'TapasForSequenceClassification', 'TransfoXLForSequenceClassification', 'UMT5ForSequenceClassification', 'XLMForSequenceClassification', 'XLMRobertaForSequenceClassification', 'XLMRobertaXLForSequenceClassification', 'XLNetForSequenceClassification', 'XmodForSequenceClassification', 'YosoForSequenceClassification'].\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "USB Network Adapters\n"
          ]
        }
      ]
    }
  ]
}